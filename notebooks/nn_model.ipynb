{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchContainerLight(object):\n",
    "    \n",
    "    def __init__(self, X, y,  batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y        \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self._iterator()\n",
    "        \n",
    "    def _iterator(self):\n",
    "        for i in range(self._number_batches()):\n",
    "            start = i * self.batch_size\n",
    "            end = (i+1) * self.batch_size\n",
    "            if self.y is not None:\n",
    "                yield self.X[start:end, :], self.y[start:end, :]\n",
    "            else:\n",
    "                yield self.X[start:end, :]  \n",
    "\n",
    "    def _number_batches(self):\n",
    "        n, _ = self.X.shape\n",
    "        return int(np.ceil(n/self.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class NNModel():\n",
    "    def __init__(self, learning_rate=0.1, batch_size=128, n_epochs=200, activation=tf.nn.relu, l2_reg=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.activation = activation\n",
    "        self.l2_reg = l2_reg\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "                \n",
    "        self._computational_graph(X, y)\n",
    "               \n",
    "        batch_container = BatchContainerLight(X, y, self.batch_size)\n",
    "\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            for X_batch, y_batch in batch_container:\n",
    "                self.session.run(self.training_op, feed_dict={self.X: X_batch, self.y: y_batch})\n",
    "            if epoch % 50 == 0:\n",
    "                mse = self.session.run(self.loss, feed_dict={self.X: X_batch, self.y: y_batch})\n",
    "                print(epoch, \"\\tMSE:\", mse)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "           \n",
    "        return self.session.run(self.outputs, feed_dict={self.X: X})\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean( (pred-y)**2)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'learning_rate': self.learning_rate,\n",
    "                'batch_size': self.batch_size,\n",
    "                'n_epochs': self.n_epochs,\n",
    "                'activation': self.activation,\n",
    "                'l2_reg': self.l2_reg}\n",
    "    \n",
    "    def set_params(self, learning_rate=None, batch_size=None, n_epochs=None, activation=None, l2_reg=None):\n",
    "        if learning_rate!=None:\n",
    "            self.learning_rate = learning_rate\n",
    "        if batch_size!=None:\n",
    "            self.batch_size = batch_size\n",
    "        if n_epochs!=None:\n",
    "            self.n_epochs = n_epochs\n",
    "        if activation!=None:\n",
    "            self.activation = activation\n",
    "        if l2_reg!=None:\n",
    "            self.l2_reg = l2_reg\n",
    "        return self\n",
    "           \n",
    "    def _computational_graph(self, X, y):\n",
    "        \n",
    "        _, n_inputs = X.shape\n",
    "        _, n_outputs = y.shape\n",
    "\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "        self.y = tf.placeholder(tf.float32, [None,  n_outputs])\n",
    "\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=self.l2_reg)\n",
    "        \n",
    "        layer_1 = tf.layers.dense(self.X, 125, activation=self.activation, kernel_regularizer=regularizer, name='layer_1')\n",
    "        layer_2 = tf.layers.dense(layer_1, 50, activation=self.activation, kernel_regularizer=regularizer, name='layer_2')\n",
    "        layer_3 = tf.layers.dense(layer_2, 25, activation=self.activation, kernel_regularizer=regularizer, name='layer_3')\n",
    "        self.outputs = tf.layers.dense(layer_3, n_outputs, activation=None, name='outputs')\n",
    "        \n",
    "        l2_loss = tf.losses.get_regularization_loss()\n",
    "        self.loss = tf.reduce_mean(tf.square(self.outputs-self.y)) + l2_loss\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        self.training_op = optimizer.minimize(self.loss)\n",
    "\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.session = tf.Session()\n",
    "        self.session.run(self.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 6.13656\n",
      "50 \tMSE: 1.49387\n",
      "100 \tMSE: 0.818143\n",
      "150 \tMSE: 0.570004\n",
      "200 \tMSE: 0.400948\n",
      "250 \tMSE: 0.293531\n",
      "300 \tMSE: 0.226772\n",
      "350 \tMSE: 0.183279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NNModel at 0x7fd637be3390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 1, 50)\n",
    "y = 3*x*x*x+5\n",
    "\n",
    "X = x.reshape(-1,1)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "model = NNModel(learning_rate=0.1, batch_size=128, n_epochs=400)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(-0.5, 1.5, 100)\n",
    "y_test = 3*x_test*x_test*x_test+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd637be3f60>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, pred)\n",
    "plt.plot(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 24.0876\n",
      "50 \tMSE: 1.45208\n",
      "100 \tMSE: 0.51705\n",
      "150 \tMSE: 0.289748\n",
      "200 \tMSE: 0.194966\n",
      "0 \tMSE: 3.5097\n",
      "50 \tMSE: 1.07717\n",
      "100 \tMSE: 0.602672\n",
      "150 \tMSE: 0.431084\n",
      "200 \tMSE: 0.319222\n",
      "0 \tMSE: 2.83923\n",
      "50 \tMSE: 2.16709\n",
      "100 \tMSE: 1.29762\n",
      "150 \tMSE: 0.930851\n",
      "200 \tMSE: 0.730649\n",
      "250 \tMSE: 0.607629\n",
      "300 \tMSE: 0.523444\n",
      "350 \tMSE: 0.460114\n",
      "400 \tMSE: 0.409126\n",
      "450 \tMSE: 0.366326\n",
      "0 \tMSE: 5.01172\n",
      "50 \tMSE: 1.3358\n",
      "100 \tMSE: 0.709489\n",
      "150 \tMSE: 0.476984\n",
      "200 \tMSE: 0.337698\n",
      "250 \tMSE: 0.246444\n",
      "300 \tMSE: 0.184514\n",
      "350 \tMSE: 0.141331\n",
      "400 \tMSE: 0.110408\n",
      "450 \tMSE: 0.0877169\n",
      "0 \tMSE: 32.1067\n",
      "50 \tMSE: 0.579835\n",
      "100 \tMSE: 0.180545\n",
      "150 \tMSE: 0.112439\n",
      "200 \tMSE: 0.0856513\n",
      "250 \tMSE: 0.0703189\n",
      "300 \tMSE: 0.0610105\n",
      "350 \tMSE: 0.0549989\n",
      "400 \tMSE: 0.0507802\n",
      "450 \tMSE: 0.253912\n",
      "500 \tMSE: 0.0523142\n",
      "550 \tMSE: 0.0483618\n",
      "600 \tMSE: 0.04609\n",
      "650 \tMSE: 0.0442609\n",
      "700 \tMSE: 0.0427038\n",
      "750 \tMSE: 0.0413226\n",
      "800 \tMSE: 0.040085\n",
      "850 \tMSE: 0.0389508\n",
      "900 \tMSE: 0.0447303\n",
      "950 \tMSE: 0.0378369\n",
      "0 \tMSE: 1.56552\n",
      "50 \tMSE: 0.836089\n",
      "100 \tMSE: 0.349988\n",
      "150 \tMSE: 0.175348\n",
      "200 \tMSE: 0.104331\n",
      "250 \tMSE: 0.0704319\n",
      "300 \tMSE: 0.0512791\n",
      "350 \tMSE: 0.0390601\n",
      "400 \tMSE: 0.0307666\n",
      "450 \tMSE: 0.02499\n",
      "500 \tMSE: 0.0209264\n",
      "550 \tMSE: 0.0180581\n",
      "600 \tMSE: 0.0160322\n",
      "650 \tMSE: 0.0146024\n",
      "700 \tMSE: 0.0135947\n",
      "750 \tMSE: 0.0128857\n",
      "800 \tMSE: 0.0123877\n",
      "850 \tMSE: 0.0120383\n",
      "900 \tMSE: 0.011793\n",
      "950 \tMSE: 0.011626\n",
      "0 \tMSE: 4.23032\n",
      "50 \tMSE: 1.88426\n",
      "100 \tMSE: 1.12014\n",
      "150 \tMSE: 0.830416\n",
      "200 \tMSE: 0.673034\n",
      "250 \tMSE: 0.561083\n",
      "300 \tMSE: 0.475019\n",
      "350 \tMSE: 0.406377\n",
      "400 \tMSE: 0.351533\n",
      "450 \tMSE: 0.307584\n",
      "500 \tMSE: 0.271773\n",
      "550 \tMSE: 0.24183\n",
      "600 \tMSE: 0.217272\n",
      "650 \tMSE: 0.196864\n",
      "700 \tMSE: 0.179544\n",
      "750 \tMSE: 0.164672\n",
      "800 \tMSE: 0.151749\n",
      "850 \tMSE: 0.14038\n",
      "900 \tMSE: 0.130178\n",
      "950 \tMSE: 0.120875\n",
      "1000 \tMSE: 0.11251\n",
      "1050 \tMSE: 0.105049\n",
      "1100 \tMSE: 0.0982837\n",
      "1150 \tMSE: 0.0921036\n",
      "1200 \tMSE: 0.0864431\n",
      "1250 \tMSE: 0.0812458\n",
      "1300 \tMSE: 0.0764766\n",
      "1350 \tMSE: 0.0722638\n",
      "1400 \tMSE: 0.0681657\n",
      "1450 \tMSE: 0.0644812\n",
      "0 \tMSE: 9.07973\n",
      "50 \tMSE: 0.753346\n",
      "100 \tMSE: 0.321328\n",
      "150 \tMSE: 0.175016\n",
      "200 \tMSE: 0.108688\n",
      "250 \tMSE: 0.0735187\n",
      "300 \tMSE: 0.0525818\n",
      "350 \tMSE: 0.0392152\n",
      "400 \tMSE: 0.0303944\n",
      "450 \tMSE: 0.0244673\n",
      "500 \tMSE: 0.0204334\n",
      "550 \tMSE: 0.0176581\n",
      "600 \tMSE: 0.0157274\n",
      "650 \tMSE: 0.0143687\n",
      "700 \tMSE: 0.0133999\n",
      "750 \tMSE: 0.0126983\n",
      "800 \tMSE: 0.0121819\n",
      "850 \tMSE: 0.0117942\n",
      "900 \tMSE: 0.0114973\n",
      "950 \tMSE: 0.0112653\n",
      "1000 \tMSE: 0.0110782\n",
      "1050 \tMSE: 0.0109249\n",
      "1100 \tMSE: 0.0107961\n",
      "1150 \tMSE: 0.0106854\n",
      "1200 \tMSE: 0.0105924\n",
      "1250 \tMSE: 0.010496\n",
      "1300 \tMSE: 0.0104124\n",
      "1350 \tMSE: 0.0104856\n",
      "1400 \tMSE: 0.0103666\n",
      "1450 \tMSE: 0.0103294\n",
      "0 \tMSE: 20.036\n",
      "50 \tMSE: 0.398132\n",
      "100 \tMSE: 0.171082\n",
      "150 \tMSE: 0.108209\n",
      "200 \tMSE: 0.0828236\n",
      "0 \tMSE: 24.0177\n",
      "50 \tMSE: 0.16256\n",
      "100 \tMSE: 0.0634791\n",
      "150 \tMSE: 0.0436419\n",
      "200 \tMSE: 0.03306\n",
      "0 \tMSE: 29.7031\n",
      "50 \tMSE: 0.832254\n",
      "100 \tMSE: 0.365301\n",
      "150 \tMSE: 0.255042\n",
      "200 \tMSE: 0.195758\n",
      "250 \tMSE: 0.159367\n",
      "300 \tMSE: 0.135007\n",
      "350 \tMSE: 0.117951\n",
      "400 \tMSE: 0.105649\n",
      "450 \tMSE: 0.0965304\n",
      "0 \tMSE: 10.8359\n",
      "50 \tMSE: 0.135121\n",
      "100 \tMSE: 0.055534\n",
      "150 \tMSE: 0.0351656\n",
      "200 \tMSE: 0.025357\n",
      "250 \tMSE: 0.0199487\n",
      "300 \tMSE: 0.0166306\n",
      "350 \tMSE: 0.0144153\n",
      "400 \tMSE: 0.0128729\n",
      "450 \tMSE: 0.0117732\n",
      "0 \tMSE: 31.7361\n",
      "50 \tMSE: 0.340115\n",
      "100 \tMSE: 0.138559\n",
      "150 \tMSE: 0.0983084\n",
      "200 \tMSE: 0.0824783\n",
      "250 \tMSE: 0.0737282\n",
      "300 \tMSE: 0.0680544\n",
      "350 \tMSE: 0.0636174\n",
      "400 \tMSE: 0.0599758\n",
      "450 \tMSE: 0.0563796\n",
      "500 \tMSE: 0.052129\n",
      "550 \tMSE: 0.0485245\n",
      "600 \tMSE: 0.0461883\n",
      "650 \tMSE: 0.0443817\n",
      "700 \tMSE: 0.0429383\n",
      "750 \tMSE: 0.0579458\n",
      "800 \tMSE: 0.0412712\n",
      "850 \tMSE: 0.0399262\n",
      "900 \tMSE: 0.0389567\n",
      "950 \tMSE: 0.0619623\n",
      "0 \tMSE: 21.6949\n",
      "50 \tMSE: 0.282129\n",
      "100 \tMSE: 0.105697\n",
      "150 \tMSE: 0.0678047\n",
      "200 \tMSE: 0.0499301\n",
      "250 \tMSE: 0.0394178\n",
      "300 \tMSE: 0.0324249\n",
      "350 \tMSE: 0.0274683\n",
      "400 \tMSE: 0.0238472\n",
      "450 \tMSE: 0.0211547\n",
      "500 \tMSE: 0.0191203\n",
      "550 \tMSE: 0.0175544\n",
      "600 \tMSE: 0.0163233\n",
      "650 \tMSE: 0.0153336\n",
      "700 \tMSE: 0.0145216\n",
      "750 \tMSE: 0.0138441\n",
      "800 \tMSE: 0.0132719\n",
      "850 \tMSE: 0.0127849\n",
      "900 \tMSE: 0.0123685\n",
      "950 \tMSE: 0.0120116\n",
      "0 \tMSE: 26.4183\n",
      "50 \tMSE: 0.668502\n",
      "100 \tMSE: 0.294214\n",
      "150 \tMSE: 0.208957\n",
      "200 \tMSE: 0.165789\n",
      "250 \tMSE: 0.137893\n",
      "300 \tMSE: 0.118425\n",
      "350 \tMSE: 0.104269\n",
      "400 \tMSE: 0.0936633\n",
      "450 \tMSE: 0.0855185\n",
      "500 \tMSE: 0.0791165\n",
      "550 \tMSE: 0.0739654\n",
      "600 \tMSE: 0.0697191\n",
      "650 \tMSE: 0.0661286\n",
      "700 \tMSE: 0.0630125\n",
      "750 \tMSE: 0.0602409\n",
      "800 \tMSE: 0.0577205\n",
      "850 \tMSE: 0.0553837\n",
      "900 \tMSE: 0.0531859\n",
      "950 \tMSE: 0.0511036\n",
      "1000 \tMSE: 0.0491312\n",
      "1050 \tMSE: 0.0472784\n",
      "1100 \tMSE: 0.0455607\n",
      "1150 \tMSE: 0.0439919\n",
      "1200 \tMSE: 0.0425772\n",
      "1250 \tMSE: 0.0413117\n",
      "1300 \tMSE: 0.0401845\n",
      "1350 \tMSE: 0.0392056\n",
      "1400 \tMSE: 0.038292\n",
      "1450 \tMSE: 0.0374827\n",
      "0 \tMSE: 22.8226\n",
      "50 \tMSE: 0.141272\n",
      "100 \tMSE: 0.0509031\n",
      "150 \tMSE: 0.0337074\n",
      "200 \tMSE: 0.024158\n",
      "250 \tMSE: 0.0188544\n",
      "300 \tMSE: 0.0164639\n",
      "350 \tMSE: 0.0133498\n",
      "400 \tMSE: 0.0120007\n",
      "450 \tMSE: 0.0110622\n",
      "500 \tMSE: 0.0103188\n",
      "550 \tMSE: 0.00975636\n",
      "600 \tMSE: 0.0105798\n",
      "650 \tMSE: 0.00913104\n",
      "700 \tMSE: 0.00884569\n",
      "750 \tMSE: 0.00862542\n",
      "800 \tMSE: 0.00844736\n",
      "850 \tMSE: 0.00847012\n",
      "900 \tMSE: 0.00829318\n",
      "950 \tMSE: 0.00817822\n",
      "1000 \tMSE: 0.00807701\n",
      "1050 \tMSE: 0.00798235\n",
      "1100 \tMSE: 0.0124199\n",
      "1150 \tMSE: 0.0082767\n",
      "1200 \tMSE: 0.007885\n",
      "1250 \tMSE: 0.00781369\n",
      "1300 \tMSE: 0.00774718\n",
      "1350 \tMSE: 0.00770903\n",
      "1400 \tMSE: 0.00763013\n",
      "1450 \tMSE: 0.00756526\n",
      "0 \tMSE: 40.6031\n",
      "50 \tMSE: 0.227325\n",
      "100 \tMSE: 0.17489\n",
      "150 \tMSE: 0.150031\n",
      "200 \tMSE: 0.132341\n",
      "0 \tMSE: 24.9645\n",
      "50 \tMSE: 0.262682\n",
      "100 \tMSE: 0.121158\n",
      "150 \tMSE: 0.0983498\n",
      "200 \tMSE: 0.0823157\n",
      "0 \tMSE: 39.304\n",
      "50 \tMSE: 0.252904\n",
      "100 \tMSE: 0.171133\n",
      "150 \tMSE: 0.143667\n",
      "200 \tMSE: 0.126023\n",
      "250 \tMSE: 0.113514\n",
      "300 \tMSE: 0.104225\n",
      "350 \tMSE: 0.0970367\n",
      "400 \tMSE: 0.0912383\n",
      "450 \tMSE: 0.0864851\n",
      "0 \tMSE: 25.0003\n",
      "50 \tMSE: 0.23744\n",
      "100 \tMSE: 0.1138\n",
      "150 \tMSE: 0.095587\n",
      "200 \tMSE: 0.0822222\n",
      "250 \tMSE: 0.0709969\n",
      "300 \tMSE: 0.0615016\n",
      "350 \tMSE: 0.0536754\n",
      "400 \tMSE: 0.0472456\n",
      "450 \tMSE: 0.0418013\n",
      "0 \tMSE: 40.905\n",
      "50 \tMSE: 0.236933\n",
      "100 \tMSE: 0.16181\n",
      "150 \tMSE: 0.138509\n",
      "200 \tMSE: 0.123962\n",
      "250 \tMSE: 0.113783\n",
      "300 \tMSE: 0.106031\n",
      "350 \tMSE: 0.0997553\n",
      "400 \tMSE: 0.0944765\n",
      "450 \tMSE: 0.0899389\n",
      "500 \tMSE: 0.0859926\n",
      "550 \tMSE: 0.0825371\n",
      "600 \tMSE: 0.0794969\n",
      "650 \tMSE: 0.0768107\n",
      "700 \tMSE: 0.074426\n",
      "750 \tMSE: 0.0722976\n",
      "800 \tMSE: 0.0703861\n",
      "850 \tMSE: 0.0686574\n",
      "900 \tMSE: 0.0670823\n",
      "950 \tMSE: 0.065636\n",
      "0 \tMSE: 25.2142\n",
      "50 \tMSE: 0.216737\n",
      "100 \tMSE: 0.102311\n",
      "150 \tMSE: 0.085511\n",
      "200 \tMSE: 0.0734484\n",
      "250 \tMSE: 0.0635167\n",
      "300 \tMSE: 0.0551963\n",
      "350 \tMSE: 0.048299\n",
      "400 \tMSE: 0.0425416\n",
      "450 \tMSE: 0.0376826\n",
      "500 \tMSE: 0.0335482\n",
      "550 \tMSE: 0.0300052\n",
      "600 \tMSE: 0.0269546\n",
      "650 \tMSE: 0.0243323\n",
      "700 \tMSE: 0.022066\n",
      "750 \tMSE: 0.020109\n",
      "800 \tMSE: 0.0184242\n",
      "850 \tMSE: 0.0169773\n",
      "900 \tMSE: 0.0157362\n",
      "950 \tMSE: 0.0146694\n",
      "0 \tMSE: 42.2447\n",
      "50 \tMSE: 0.20402\n",
      "100 \tMSE: 0.149275\n",
      "150 \tMSE: 0.125642\n",
      "200 \tMSE: 0.110737\n",
      "250 \tMSE: 0.100775\n",
      "300 \tMSE: 0.0938202\n",
      "350 \tMSE: 0.0886847\n",
      "400 \tMSE: 0.0846654\n",
      "450 \tMSE: 0.081371\n",
      "500 \tMSE: 0.0785846\n",
      "550 \tMSE: 0.0761799\n",
      "600 \tMSE: 0.0740771\n",
      "650 \tMSE: 0.0722219\n",
      "700 \tMSE: 0.0705748\n",
      "750 \tMSE: 0.0690845\n",
      "800 \tMSE: 0.0677533\n",
      "850 \tMSE: 0.0665243\n",
      "900 \tMSE: 0.0653749\n",
      "950 \tMSE: 0.0642724\n",
      "1000 \tMSE: 0.0631604\n",
      "1050 \tMSE: 0.0619528\n",
      "1100 \tMSE: 0.0605509\n",
      "1150 \tMSE: 0.0589231\n",
      "1200 \tMSE: 0.0571368\n",
      "1250 \tMSE: 0.0552372\n",
      "1300 \tMSE: 0.0535405\n",
      "1350 \tMSE: 0.0521699\n",
      "1400 \tMSE: 0.0509823\n",
      "1450 \tMSE: 0.0499477\n",
      "0 \tMSE: 24.5032\n",
      "50 \tMSE: 0.281074\n",
      "100 \tMSE: 0.114536\n",
      "150 \tMSE: 0.0916343\n",
      "200 \tMSE: 0.0774492\n",
      "250 \tMSE: 0.067031\n",
      "300 \tMSE: 0.0588068\n",
      "350 \tMSE: 0.0520984\n",
      "400 \tMSE: 0.0465454\n",
      "450 \tMSE: 0.0419137\n",
      "500 \tMSE: 0.0380285\n",
      "550 \tMSE: 0.0347499\n",
      "600 \tMSE: 0.0319632\n",
      "650 \tMSE: 0.0295752\n",
      "700 \tMSE: 0.0275106\n",
      "750 \tMSE: 0.025709\n",
      "800 \tMSE: 0.0241225\n",
      "850 \tMSE: 0.0227134\n",
      "900 \tMSE: 0.0214522\n",
      "950 \tMSE: 0.0203157\n",
      "1000 \tMSE: 0.0192858\n",
      "1050 \tMSE: 0.0183481\n",
      "1100 \tMSE: 0.0174917\n",
      "1150 \tMSE: 0.0167079\n",
      "1200 \tMSE: 0.0159894\n",
      "1250 \tMSE: 0.0153301\n",
      "1300 \tMSE: 0.0147246\n",
      "1350 \tMSE: 0.0141691\n",
      "1400 \tMSE: 0.0139736\n",
      "1450 \tMSE: 0.0132223\n",
      "0 \tMSE: 3.99576\n",
      "50 \tMSE: 5.02174\n",
      "100 \tMSE: 2.12307\n",
      "150 \tMSE: 1.22462\n",
      "200 \tMSE: 0.708961\n",
      "0 \tMSE: 2.21964\n",
      "50 \tMSE: 0.423784\n",
      "100 \tMSE: 0.0284055\n",
      "150 \tMSE: 0.0233017\n",
      "200 \tMSE: 0.0196109\n",
      "0 \tMSE: 4.06891\n",
      "50 \tMSE: 2.67157\n",
      "100 \tMSE: 1.03486\n",
      "150 \tMSE: 1.01491\n",
      "200 \tMSE: 0.916623\n",
      "250 \tMSE: 8.39942\n",
      "300 \tMSE: 1.35694\n",
      "350 \tMSE: 1.06791\n",
      "400 \tMSE: 0.788334\n",
      "450 \tMSE: 0.684651\n",
      "0 \tMSE: 2.66625\n",
      "50 \tMSE: 1.61596\n",
      "100 \tMSE: 10.1872\n",
      "150 \tMSE: 2.08085\n",
      "200 \tMSE: 0.629365\n",
      "250 \tMSE: 0.160445\n",
      "300 \tMSE: 0.0424122\n",
      "350 \tMSE: 0.0550611\n",
      "400 \tMSE: 0.0360441\n",
      "450 \tMSE: 0.0288855\n",
      "0 \tMSE: 24.9972\n",
      "50 \tMSE: 3.31207\n",
      "100 \tMSE: 1.1167\n",
      "150 \tMSE: 0.814823\n",
      "200 \tMSE: 0.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 \tMSE: 0.682061\n",
      "300 \tMSE: 0.881965\n",
      "350 \tMSE: 0.702595\n",
      "400 \tMSE: 0.780035\n",
      "450 \tMSE: 0.778993\n",
      "500 \tMSE: 0.698511\n",
      "550 \tMSE: 0.622119\n",
      "600 \tMSE: 3.60287\n",
      "650 \tMSE: 8.23773\n",
      "700 \tMSE: 2.05446\n",
      "750 \tMSE: 1.00836\n",
      "800 \tMSE: 0.742665\n",
      "850 \tMSE: 0.653457\n",
      "900 \tMSE: 0.631956\n",
      "950 \tMSE: 0.620887\n",
      "0 \tMSE: 2.08242\n",
      "50 \tMSE: 0.313856\n",
      "100 \tMSE: 0.0404105\n",
      "150 \tMSE: 0.0441198\n",
      "200 \tMSE: 0.198126\n",
      "250 \tMSE: 0.0532837\n",
      "300 \tMSE: 0.0322129\n",
      "350 \tMSE: 0.0226013\n",
      "400 \tMSE: 0.0195784\n",
      "450 \tMSE: 0.0174806\n",
      "500 \tMSE: 0.0273112\n",
      "550 \tMSE: 0.0182877\n",
      "600 \tMSE: 1.05464\n",
      "650 \tMSE: 33.0466\n",
      "700 \tMSE: 28.6509\n",
      "750 \tMSE: 14.013\n",
      "800 \tMSE: 10.5257\n",
      "850 \tMSE: 5.38508\n",
      "900 \tMSE: 3.34227\n",
      "950 \tMSE: 2.22833\n",
      "0 \tMSE: 3.13646\n",
      "50 \tMSE: 4.15936\n",
      "100 \tMSE: 2.54036\n",
      "150 \tMSE: 1.73955\n",
      "200 \tMSE: 0.771722\n",
      "250 \tMSE: 0.661463\n",
      "300 \tMSE: 0.670262\n",
      "350 \tMSE: 0.738054\n",
      "400 \tMSE: 1.32674\n",
      "450 \tMSE: 0.633662\n",
      "500 \tMSE: 0.64747\n",
      "550 \tMSE: 0.632787\n",
      "600 \tMSE: 1.14109\n",
      "650 \tMSE: 0.687825\n",
      "700 \tMSE: 0.672281\n",
      "750 \tMSE: 0.660622\n",
      "800 \tMSE: 0.619484\n",
      "850 \tMSE: 0.618871\n",
      "900 \tMSE: 0.622433\n",
      "950 \tMSE: 0.61436\n",
      "1000 \tMSE: 0.616415\n",
      "1050 \tMSE: 0.61454\n",
      "1100 \tMSE: 0.615796\n",
      "1150 \tMSE: 0.619618\n",
      "1200 \tMSE: 0.619424\n",
      "1250 \tMSE: 0.615559\n",
      "1300 \tMSE: 0.619005\n",
      "1350 \tMSE: 0.614015\n",
      "1400 \tMSE: 0.615683\n",
      "1450 \tMSE: 0.615683\n",
      "0 \tMSE: 2.80863\n",
      "50 \tMSE: 0.486757\n",
      "100 \tMSE: 0.0761865\n",
      "150 \tMSE: 0.017723\n",
      "200 \tMSE: 0.0200671\n",
      "250 \tMSE: 0.0158115\n",
      "300 \tMSE: 0.0139613\n",
      "350 \tMSE: 0.0142972\n",
      "400 \tMSE: 0.0169145\n",
      "450 \tMSE: 0.0143532\n",
      "500 \tMSE: 0.0134404\n",
      "550 \tMSE: 0.0132788\n",
      "600 \tMSE: 0.0341229\n",
      "650 \tMSE: 0.0135147\n",
      "700 \tMSE: 0.0149531\n",
      "750 \tMSE: 0.0139148\n",
      "800 \tMSE: 0.0133179\n",
      "850 \tMSE: 0.0125226\n",
      "900 \tMSE: 0.0388832\n",
      "950 \tMSE: 0.0117638\n",
      "1000 \tMSE: 0.0125046\n",
      "1050 \tMSE: 0.0163547\n",
      "1100 \tMSE: 0.0133109\n",
      "1150 \tMSE: 0.0116034\n",
      "1200 \tMSE: 0.0129132\n",
      "1250 \tMSE: 0.0133407\n",
      "1300 \tMSE: 0.015063\n",
      "1350 \tMSE: 0.0114355\n",
      "1400 \tMSE: 0.0115854\n",
      "1450 \tMSE: 0.0114742\n",
      "0 \tMSE: 4.82084\n",
      "50 \tMSE: 1.8558\n",
      "100 \tMSE: 1.08099\n",
      "150 \tMSE: 1.35994\n",
      "200 \tMSE: 0.853984\n",
      "0 \tMSE: 7.4325\n",
      "50 \tMSE: 0.468765\n",
      "100 \tMSE: 0.0601818\n",
      "150 \tMSE: 0.059691\n",
      "200 \tMSE: 0.0407717\n",
      "0 \tMSE: 2.77643\n",
      "50 \tMSE: 1.89849\n",
      "100 \tMSE: 2.40715\n",
      "150 \tMSE: 1.14022\n",
      "200 \tMSE: 1.60229\n",
      "250 \tMSE: 0.738742\n",
      "300 \tMSE: 3.86083\n",
      "350 \tMSE: 4.15807\n",
      "400 \tMSE: 2.23076\n",
      "450 \tMSE: 1.16188\n",
      "0 \tMSE: 4.06501\n",
      "50 \tMSE: 0.499896\n",
      "100 \tMSE: 0.0798509\n",
      "150 \tMSE: 0.0259115\n",
      "200 \tMSE: 0.0215663\n",
      "250 \tMSE: 0.0199752\n",
      "300 \tMSE: 0.018426\n",
      "350 \tMSE: 0.0175017\n",
      "400 \tMSE: 0.0203229\n",
      "450 \tMSE: 0.0261408\n",
      "0 \tMSE: 10.2596\n",
      "50 \tMSE: 1.98651\n",
      "100 \tMSE: 1.03124\n",
      "150 \tMSE: 3.33168\n",
      "200 \tMSE: 1.56771\n",
      "250 \tMSE: 1.02844\n",
      "300 \tMSE: 0.787094\n",
      "350 \tMSE: 0.841227\n",
      "400 \tMSE: 0.748366\n",
      "450 \tMSE: 1.48023\n",
      "500 \tMSE: 0.624794\n",
      "550 \tMSE: 0.935108\n",
      "600 \tMSE: 0.583674\n",
      "650 \tMSE: 0.657545\n",
      "700 \tMSE: 1.37531\n",
      "750 \tMSE: 0.788002\n",
      "800 \tMSE: 1.57001\n",
      "850 \tMSE: 0.519518\n",
      "900 \tMSE: 0.702644\n",
      "950 \tMSE: 1.52089\n",
      "0 \tMSE: 5.0675\n",
      "50 \tMSE: 0.503512\n",
      "100 \tMSE: 0.0684106\n",
      "150 \tMSE: 0.0752835\n",
      "200 \tMSE: 0.0198548\n",
      "250 \tMSE: 0.023112\n",
      "300 \tMSE: 0.0416884\n",
      "350 \tMSE: 0.0161317\n",
      "400 \tMSE: 0.0226078\n",
      "450 \tMSE: 0.0292748\n",
      "500 \tMSE: 0.0150046\n",
      "550 \tMSE: 0.0220649\n",
      "600 \tMSE: 0.0759809\n",
      "650 \tMSE: 0.020907\n",
      "700 \tMSE: 0.0140186\n",
      "750 \tMSE: 0.0172979\n",
      "800 \tMSE: 0.0336758\n",
      "850 \tMSE: 0.0132731\n",
      "900 \tMSE: 0.0160824\n",
      "950 \tMSE: 0.0124645\n",
      "0 \tMSE: 3.73248\n",
      "50 \tMSE: 1.89051\n",
      "100 \tMSE: 1.0228\n",
      "150 \tMSE: 0.934375\n",
      "200 \tMSE: 0.777981\n",
      "250 \tMSE: 0.904376\n",
      "300 \tMSE: 1.34865\n",
      "350 \tMSE: 0.805934\n",
      "400 \tMSE: 2.795\n",
      "450 \tMSE: 0.971647\n",
      "500 \tMSE: 0.882092\n",
      "550 \tMSE: 1.70366\n",
      "600 \tMSE: 0.647433\n",
      "650 \tMSE: 0.819243\n",
      "700 \tMSE: 5.54837\n",
      "750 \tMSE: 1.24816\n",
      "800 \tMSE: 0.916956\n",
      "850 \tMSE: 10.8749\n",
      "900 \tMSE: 1.84824\n",
      "950 \tMSE: 0.840613\n",
      "1000 \tMSE: 0.745526\n",
      "1050 \tMSE: 0.170399\n",
      "1100 \tMSE: 0.109267\n",
      "1150 \tMSE: 0.0786231\n",
      "1200 \tMSE: 0.101485\n",
      "1250 \tMSE: 0.183903\n",
      "1300 \tMSE: 0.0780323\n",
      "1350 \tMSE: 0.0537193\n",
      "1400 \tMSE: 0.11244\n",
      "1450 \tMSE: 0.0570385\n",
      "0 \tMSE: 7.75913\n",
      "50 \tMSE: 0.67373\n",
      "100 \tMSE: 0.114284\n",
      "150 \tMSE: 0.121118\n",
      "200 \tMSE: 0.0204428\n",
      "250 \tMSE: 0.0186215\n",
      "300 \tMSE: 0.0207168\n",
      "350 \tMSE: 0.0222315\n",
      "400 \tMSE: 0.0207369\n",
      "450 \tMSE: 0.0159142\n",
      "500 \tMSE: 0.01854\n",
      "550 \tMSE: 0.0638331\n",
      "600 \tMSE: 0.016816\n",
      "650 \tMSE: 0.0392957\n",
      "700 \tMSE: 0.0154085\n",
      "750 \tMSE: 0.0310142\n",
      "800 \tMSE: 0.0145417\n",
      "850 \tMSE: 0.0497725\n",
      "900 \tMSE: 0.0140659\n",
      "950 \tMSE: 0.0122893\n",
      "1000 \tMSE: 0.013493\n",
      "1050 \tMSE: 0.0120454\n",
      "1100 \tMSE: 0.01183\n",
      "1150 \tMSE: 0.0118157\n",
      "1200 \tMSE: 0.0123548\n",
      "1250 \tMSE: 0.0118173\n",
      "1300 \tMSE: 0.0122526\n",
      "1350 \tMSE: 0.0118885\n",
      "1400 \tMSE: 0.0116271\n",
      "1450 \tMSE: 0.0140023\n",
      "0 \tMSE: 25.4681\n",
      "50 \tMSE: 1.2993\n",
      "100 \tMSE: 1.04594\n",
      "150 \tMSE: 0.512685\n",
      "200 \tMSE: 0.333442\n",
      "0 \tMSE: 20.9021\n",
      "50 \tMSE: 0.56625\n",
      "100 \tMSE: 0.302198\n",
      "150 \tMSE: 0.17314\n",
      "200 \tMSE: 0.112586\n",
      "0 \tMSE: 27.0144\n",
      "50 \tMSE: 1.28809\n",
      "100 \tMSE: 1.06573\n",
      "150 \tMSE: 0.866677\n",
      "200 \tMSE: 0.371104\n",
      "250 \tMSE: 0.289927\n",
      "300 \tMSE: 0.198961\n",
      "350 \tMSE: 0.16041\n",
      "400 \tMSE: 0.133238\n",
      "450 \tMSE: 0.115123\n",
      "0 \tMSE: 19.5282\n",
      "50 \tMSE: 0.548029\n",
      "100 \tMSE: 0.284272\n",
      "150 \tMSE: 0.17306\n",
      "200 \tMSE: 0.118164\n",
      "250 \tMSE: 0.0853872\n",
      "300 \tMSE: 0.0638358\n",
      "350 \tMSE: 0.0492304\n",
      "400 \tMSE: 0.0392449\n",
      "450 \tMSE: 0.0322521\n",
      "0 \tMSE: 26.6352\n",
      "50 \tMSE: 1.28647\n",
      "100 \tMSE: 1.07459\n",
      "150 \tMSE: 0.908914\n",
      "200 \tMSE: 0.427906\n",
      "250 \tMSE: 0.268283\n",
      "300 \tMSE: 0.205611\n",
      "350 \tMSE: 0.163941\n",
      "400 \tMSE: 0.136767\n",
      "450 \tMSE: 0.119406\n",
      "500 \tMSE: 0.103451\n",
      "550 \tMSE: 0.106942\n",
      "600 \tMSE: 0.0843699\n",
      "650 \tMSE: 0.081881\n",
      "700 \tMSE: 0.0732533\n",
      "750 \tMSE: 0.0727752\n",
      "800 \tMSE: 0.0663936\n",
      "850 \tMSE: 0.0624778\n",
      "900 \tMSE: 0.0670041\n",
      "950 \tMSE: 0.0589746\n",
      "0 \tMSE: 19.2726\n",
      "50 \tMSE: 0.499647\n",
      "100 \tMSE: 0.289571\n",
      "150 \tMSE: 0.187015\n",
      "200 \tMSE: 0.1295\n",
      "250 \tMSE: 0.0933006\n",
      "300 \tMSE: 0.0691761\n",
      "350 \tMSE: 0.0528927\n",
      "400 \tMSE: 0.0418074\n",
      "450 \tMSE: 0.0340879\n",
      "500 \tMSE: 0.0285799\n",
      "550 \tMSE: 0.0245668\n",
      "600 \tMSE: 0.0215878\n",
      "650 \tMSE: 0.0193369\n",
      "700 \tMSE: 0.0176061\n",
      "750 \tMSE: 0.0162522\n",
      "800 \tMSE: 0.0151755\n",
      "850 \tMSE: 0.0143075\n",
      "900 \tMSE: 0.0141662\n",
      "950 \tMSE: 0.0133217\n",
      "0 \tMSE: 22.0097\n",
      "50 \tMSE: 1.27422\n",
      "100 \tMSE: 1.06999\n",
      "150 \tMSE: 0.92444\n",
      "200 \tMSE: 0.63387\n",
      "250 \tMSE: 0.343944\n",
      "300 \tMSE: 0.182358\n",
      "350 \tMSE: 0.143241\n",
      "400 \tMSE: 0.119368\n",
      "450 \tMSE: 0.103058\n",
      "500 \tMSE: 0.0913402\n",
      "550 \tMSE: 0.082646\n",
      "600 \tMSE: 0.0760425\n",
      "650 \tMSE: 0.0709298\n",
      "700 \tMSE: 0.150503\n",
      "750 \tMSE: 0.0663599\n",
      "800 \tMSE: 0.0625065\n",
      "850 \tMSE: 0.0600815\n",
      "900 \tMSE: 0.0581176\n",
      "950 \tMSE: 0.0564625\n",
      "1000 \tMSE: 0.055038\n",
      "1050 \tMSE: 0.0687785\n",
      "1100 \tMSE: 0.0540144\n",
      "1150 \tMSE: 0.0525827\n",
      "1200 \tMSE: 0.0515389\n",
      "1250 \tMSE: 0.0506438\n",
      "1300 \tMSE: 0.0498438\n",
      "1350 \tMSE: 0.0491145\n",
      "1400 \tMSE: 0.048442\n",
      "1450 \tMSE: 0.0478166\n",
      "0 \tMSE: 19.9307\n",
      "50 \tMSE: 0.528409\n",
      "100 \tMSE: 0.280882\n",
      "150 \tMSE: 0.163946\n",
      "200 \tMSE: 0.10886\n",
      "250 \tMSE: 0.0773734\n",
      "300 \tMSE: 0.0571313\n",
      "350 \tMSE: 0.0436834\n",
      "400 \tMSE: 0.0347098\n",
      "450 \tMSE: 0.0286252\n",
      "500 \tMSE: 0.0243837\n",
      "550 \tMSE: 0.021339\n",
      "600 \tMSE: 0.0190916\n",
      "650 \tMSE: 0.0173892\n",
      "700 \tMSE: 0.016069\n",
      "750 \tMSE: 0.0313267\n",
      "800 \tMSE: 0.0149654\n",
      "850 \tMSE: 0.0139573\n",
      "900 \tMSE: 0.01336\n",
      "950 \tMSE: 0.0142252\n",
      "1000 \tMSE: 0.0130449\n",
      "1050 \tMSE: 0.0124804\n",
      "1100 \tMSE: 0.012043\n",
      "1150 \tMSE: 0.0169314\n",
      "1200 \tMSE: 0.0120622\n",
      "1250 \tMSE: 0.011635\n",
      "1300 \tMSE: 0.0113153\n",
      "1350 \tMSE: 0.011073\n",
      "1400 \tMSE: 0.0118829\n",
      "1450 \tMSE: 0.0111217\n",
      "0 \tMSE: 24.3321\n",
      "50 \tMSE: 0.471125\n",
      "100 \tMSE: 0.275265\n",
      "150 \tMSE: 0.222557\n",
      "200 \tMSE: 0.197763\n",
      "250 \tMSE: 0.183739\n",
      "300 \tMSE: 0.17488\n",
      "350 \tMSE: 0.168877\n",
      "400 \tMSE: 0.164618\n",
      "450 \tMSE: 0.161496\n",
      "500 \tMSE: 0.15914\n",
      "550 \tMSE: 0.157311\n",
      "600 \tMSE: 0.155854\n",
      "650 \tMSE: 0.154664\n",
      "700 \tMSE: 0.15367\n",
      "750 \tMSE: 0.152821\n",
      "800 \tMSE: 0.152084\n",
      "850 \tMSE: 0.151434\n",
      "900 \tMSE: 0.150852\n",
      "950 \tMSE: 0.150324\n",
      "1000 \tMSE: 0.149841\n",
      "1050 \tMSE: 0.149394\n",
      "1100 \tMSE: 0.148976\n",
      "1150 \tMSE: 0.148584\n",
      "1200 \tMSE: 0.148212\n",
      "1250 \tMSE: 0.147858\n",
      "1300 \tMSE: 0.147519\n",
      "1350 \tMSE: 0.147214\n",
      "1400 \tMSE: 0.146889\n",
      "1450 \tMSE: 0.146584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=<__main__.NNModel object at 0x7fd619a925c0>,\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.1, 0.05, 0.01], 'activation': [<function relu at 0x7fd64c38b7b8>, <function tanh at 0x7fd64c274840>], 'n_epochs': [250, 500, 1000, 1500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "parameters = {'learning_rate':[0.1, 0.05, 0.01], 'activation':[tf.nn.relu, tf.nn.tanh], 'n_epochs': [250, 500, 1000, 1500]}\n",
    "\n",
    "gs = GridSearchCV(NNModel(), parameters, cv=2, scoring=mse)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.73039782,  1.07990539,  1.63291574,  2.30943906,  0.80185938,\n",
       "         1.14455235,  1.76275623,  2.34843159,  0.96644688,  1.51771069,\n",
       "         1.6589005 ,  2.24972129,  0.66709554,  0.94695032,  1.39211428,\n",
       "         1.99630415,  0.73581338,  1.01109362,  1.44122183,  1.95377362,\n",
       "         0.70143044,  0.98322666,  1.39276338,  1.89491081]),\n",
       " 'std_fit_time': array([  3.83007526e-03,   7.34366179e-02,   2.13534832e-02,\n",
       "          3.15274000e-02,   2.40714550e-02,   1.39092207e-02,\n",
       "          1.86401606e-02,   3.38039398e-02,   2.82871723e-02,\n",
       "          3.98104191e-01,   3.54750156e-02,   8.10158253e-02,\n",
       "          3.59976292e-03,   5.71719408e-02,   4.81498241e-03,\n",
       "          1.45117044e-02,   2.35533714e-03,   7.78062344e-02,\n",
       "          3.70475054e-02,   1.90674067e-02,   1.23381615e-04,\n",
       "          5.62924147e-02,   1.48632526e-02,   3.85224819e-02]),\n",
       " 'mean_score_time': array([ 0.02673173,  0.02643967,  0.03208756,  0.02950788,  0.03354323,\n",
       "         0.03023171,  0.02924562,  0.02983081,  0.02964389,  0.03244233,\n",
       "         0.02788794,  0.02694464,  0.02757752,  0.02551091,  0.0253129 ,\n",
       "         0.0274955 ,  0.02622962,  0.02568042,  0.02584457,  0.02642274,\n",
       "         0.02609825,  0.02948856,  0.02564728,  0.02650511]),\n",
       " 'std_score_time': array([  1.02281570e-04,   4.76837158e-06,   4.07695770e-03,\n",
       "          2.17270851e-03,   3.08072567e-03,   2.54893303e-03,\n",
       "          7.11441040e-04,   1.46985054e-04,   2.31230259e-03,\n",
       "          4.28318977e-03,   2.43544579e-04,   2.95877457e-04,\n",
       "          2.45606899e-03,   2.82645226e-04,   1.37090683e-04,\n",
       "          1.04773045e-03,   1.43051147e-04,   3.90410423e-04,\n",
       "          5.86271286e-04,   1.90496445e-04,   6.38484955e-04,\n",
       "          7.97033310e-04,   5.97596169e-04,   9.80496407e-04]),\n",
       " 'param_activation': masked_array(data = [<function relu at 0x7fd64c38b7b8> <function relu at 0x7fd64c38b7b8>\n",
       "  <function relu at 0x7fd64c38b7b8> <function relu at 0x7fd64c38b7b8>\n",
       "  <function relu at 0x7fd64c38b7b8> <function relu at 0x7fd64c38b7b8>\n",
       "  <function relu at 0x7fd64c38b7b8> <function relu at 0x7fd64c38b7b8>\n",
       "  <function relu at 0x7fd64c38b7b8> <function relu at 0x7fd64c38b7b8>\n",
       "  <function relu at 0x7fd64c38b7b8> <function relu at 0x7fd64c38b7b8>\n",
       "  <function tanh at 0x7fd64c274840> <function tanh at 0x7fd64c274840>\n",
       "  <function tanh at 0x7fd64c274840> <function tanh at 0x7fd64c274840>\n",
       "  <function tanh at 0x7fd64c274840> <function tanh at 0x7fd64c274840>\n",
       "  <function tanh at 0x7fd64c274840> <function tanh at 0x7fd64c274840>\n",
       "  <function tanh at 0x7fd64c274840> <function tanh at 0x7fd64c274840>\n",
       "  <function tanh at 0x7fd64c274840> <function tanh at 0x7fd64c274840>],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_learning_rate': masked_array(data = [0.1 0.1 0.1 0.1 0.05 0.05 0.05 0.05 0.01 0.01 0.01 0.01 0.1 0.1 0.1 0.1\n",
       "  0.05 0.05 0.05 0.05 0.01 0.01 0.01 0.01],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_epochs': masked_array(data = [250 500 1000 1500 250 500 1000 1500 250 500 1000 1500 250 500 1000 1500\n",
       "  250 500 1000 1500 250 500 1000 1500],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 250},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 500},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 1000},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 1500},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 250},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 500},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 1000},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 1500},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 250},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 500},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 1000},\n",
       "  {'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 1500},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 250},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 500},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 1000},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.1,\n",
       "   'n_epochs': 1500},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 250},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 500},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 1000},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.05,\n",
       "   'n_epochs': 1500},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 250},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 500},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 1000},\n",
       "  {'activation': <function tensorflow.python.ops.math_ops.tanh(x, name=None)>,\n",
       "   'learning_rate': 0.01,\n",
       "   'n_epochs': 1500}],\n",
       " 'split0_test_score': array([ -1.51851874e+00,  -1.90980008e+00,  -1.39940802e-01,\n",
       "         -8.48504363e-01,  -1.47320972e+00,  -1.48281472e+00,\n",
       "         -3.87182158e-01,  -5.10983894e-01,  -1.85934700e+00,\n",
       "         -1.90772150e+00,  -1.97700439e+00,  -1.03211046e+00,\n",
       "         -1.39195359e+00,  -3.22588407e+00,  -1.80789080e+00,\n",
       "         -1.76549593e+00,  -2.17708344e+00,  -2.05406416e+00,\n",
       "         -1.60138085e+00,  -1.06108611e-03,  -5.83799473e-01,\n",
       "         -1.12215682e+00,  -6.16037227e-01,  -2.83893034e+00]),\n",
       " 'split1_test_score': array([-1.58375292, -1.60687161, -2.429245  , -1.85388285, -1.5740732 ,\n",
       "        -1.70628456, -1.74707003, -1.62080044, -1.28111798, -1.45022319,\n",
       "        -1.66104027, -1.61324471, -2.14489289, -2.3556302 , -2.32074747,\n",
       "        -2.37311893, -2.17874798, -2.53242047, -2.44859782, -2.41537967,\n",
       "        -1.64197797, -1.66158189, -1.73604589, -1.83277599]),\n",
       " 'mean_test_score': array([-1.55113583, -1.75833584, -1.2845929 , -1.35119361, -1.52364146,\n",
       "        -1.59454964, -1.0671261 , -1.06589217, -1.57023249, -1.67897235,\n",
       "        -1.81902233, -1.32267759, -1.76842324, -2.79075713, -2.06431914,\n",
       "        -2.06930743, -2.17791571, -2.29324232, -2.02498933, -1.20822038,\n",
       "        -1.11288872, -1.39186935, -1.17604156, -2.33585317]),\n",
       " 'std_test_score': array([  3.26170897e-02,   1.51464235e-01,   1.14465210e+00,\n",
       "          5.02689246e-01,   5.04317357e-02,   1.11734919e-01,\n",
       "          6.79943938e-01,   5.54908272e-01,   2.89114508e-01,\n",
       "          2.28749154e-01,   1.57982063e-01,   2.90567124e-01,\n",
       "          3.76469648e-01,   4.35126934e-01,   2.56428336e-01,\n",
       "          3.03811501e-01,   8.32271790e-04,   2.39178155e-01,\n",
       "          4.23608489e-01,   1.20715929e+00,   5.29089249e-01,\n",
       "          2.69712539e-01,   5.60004330e-01,   5.03077175e-01]),\n",
       " 'rank_test_score': array([11, 15,  6,  8, 10, 13,  2,  1, 12, 14, 17,  7, 16, 24, 19, 20, 21,\n",
       "        22, 18,  5,  3,  9,  4, 23], dtype=int32),\n",
       " 'split0_train_score': array([-0.01665026, -0.01765199, -0.00788374, -0.00336023, -0.01261215,\n",
       "        -0.0174116 , -0.00212501, -0.00265283, -0.0178522 , -0.01674904,\n",
       "        -0.01762696, -0.00452098, -0.64200335, -0.81270639, -0.61390145,\n",
       "        -0.61435546, -0.62931181, -0.62044622, -0.61090165, -0.0021532 ,\n",
       "        -0.01355211, -0.00907141, -0.00553987, -0.02802699]),\n",
       " 'split1_train_score': array([-0.0019579 , -0.00202373, -0.01120332, -0.00347059, -0.00193695,\n",
       "        -0.00243778, -0.00267449, -0.003536  , -0.00169483, -0.0016889 ,\n",
       "        -0.00222433, -0.00204564, -0.02313932, -0.0117248 , -0.01284612,\n",
       "        -0.01162935, -0.01613713, -0.01322736, -0.01123797, -0.01122593,\n",
       "        -0.00375084, -0.00215131, -0.0024664 , -0.00312959]),\n",
       " 'mean_train_score': array([-0.00930408, -0.00983786, -0.00954353, -0.00341541, -0.00727455,\n",
       "        -0.00992469, -0.00239975, -0.00309441, -0.00977352, -0.00921897,\n",
       "        -0.00992565, -0.00328331, -0.33257133, -0.41221559, -0.31337379,\n",
       "        -0.31299241, -0.32272447, -0.31683679, -0.31106981, -0.00668957,\n",
       "        -0.00865148, -0.00561136, -0.00400314, -0.01557829]),\n",
       " 'std_train_score': array([  7.34618378e-03,   7.81412727e-03,   1.65978815e-03,\n",
       "          5.51790740e-05,   5.33759979e-03,   7.48691220e-03,\n",
       "          2.74742239e-04,   4.41585570e-04,   8.07868282e-03,\n",
       "          7.53006967e-03,   7.70131606e-03,   1.23767062e-03,\n",
       "          3.09432014e-01,   4.00490795e-01,   3.00527665e-01,\n",
       "          3.01363056e-01,   3.06587341e-01,   3.03609428e-01,\n",
       "          2.99831841e-01,   4.53636256e-03,   4.90063353e-03,\n",
       "          3.46004720e-03,   1.53673534e-03,   1.24486965e-02])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'batch_size': 128,\n",
       " 'n_epochs': 1500,\n",
       " 'activation': <function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>,\n",
       " 'l2_reg': 0.01}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
